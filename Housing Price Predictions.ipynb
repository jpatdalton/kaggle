{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.cross_validation import KFold\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import timeit\n",
    "import datetime\n",
    "import random\n",
    "import copy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../housing-prices/train.csv')\n",
    "test_df = pd.read_csv('../housing-prices/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prices = train_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_train = train_df.shape[0]\n",
    "n_test = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_prices = np.log(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist = sns.distplot(np.log(prices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlations = train_df.select_dtypes(include=['float64','int64']).corr()\n",
    "print correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,22))\n",
    "sns.heatmap(correlations, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.drop(['Id', 'SalePrice'], axis=1, inplace=True)\n",
    "test_df.drop(['Id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comb_ds = pd.concat((train_df, test_df)).reset_index(drop=True)\n",
    "comb_ds = pd.get_dummies(comb_ds)\n",
    "comb_ds = comb_ds.fillna(comb_ds.mean())\n",
    "\n",
    "\n",
    "'''\n",
    "object_cols = train_df.select_dtypes(include=['O']).columns\n",
    "\n",
    "comb_ds = pd.concat((train_df, test_df)).reset_index(drop=True)\n",
    "try:\n",
    "    for cat_col in object_cols:\n",
    "        comb_ds[cat_col] = pd.factorize(comb_ds[cat_col])[0]\n",
    "except ValueError,e:\n",
    "    print ValueError, e, cat_col\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comb_ds.drop(['1stFlrSF','GarageCars'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = comb_ds[:n_train]\n",
    "test_df = comb_ds[n_train:]\n",
    "train_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comb_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_it(params, num_kf, kfolds, n_rounds, score, note=' no note'):\n",
    "    \"\"\"Function to log parameters for validation predictions\"\"\"\n",
    "    f = open('kf_output.txt', 'a')\n",
    "    f.write('**NEW**/n')\n",
    "    f.write('\\n')\n",
    "    f.write('num_kf: ' + str(num_kf))\n",
    "    f.write('\\nkfolds: ' + str(kfolds))\n",
    "    f.write('\\nn_rounds: ' + str(n_rounds))\n",
    "    f.write('\\n')\n",
    "    f.write(str(params))\n",
    "    f.write('\\n')\n",
    "    f.write('SCORE: ' + str(score))\n",
    "    f.write('\\n')\n",
    "    f.write('note: '+ note)\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "\n",
    "I've implemented my own grid searches below to find the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_it(params, max_rounds, n_fold, early_stopping_rounds = 25):\n",
    "    n_rounds=max_rounds\n",
    "\n",
    "    dtrain = xgb.DMatrix(train_df, label = log_prices)\n",
    "\n",
    "    res = xgb.cv(params, dtrain, num_boost_round=n_rounds, nfold=n_fold, seed=21, stratified=False,\n",
    "                 early_stopping_rounds = early_stopping_rounds, verbose_eval=500, show_stdv=True)\n",
    "    score = res.iloc[len(res)-1][0]\n",
    "    print 'Num Rounds for score: ', score, ' = ', len(res)-1\n",
    "    log_it(params, 0, 6, n_rounds,score)\n",
    "       \n",
    "    return score\n",
    "\n",
    "def grid_search(params_dict, params_orig, n_folds, max_rounds):\n",
    "    \n",
    "    min_score = sys.maxint\n",
    "    min_params = ''\n",
    "    \n",
    "    for param in params_dict:\n",
    "        params_orig[param] = params_dict[param][0]\n",
    "\n",
    "    params_arr = list([copy.deepcopy(params_orig)])\n",
    "    for param in params_dict:\n",
    "        extend_params = list()\n",
    "        for i, el in enumerate(params_dict[param]):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            if params_arr:\n",
    "                for param_arr in params_arr:\n",
    "                    temp_param_arr = dict(param_arr)\n",
    "                    temp_param_arr[param] = el\n",
    "                    extend_params.append(temp_param_arr)\n",
    "        params_arr.extend(extend_params)\n",
    "\n",
    "    print 'Length of parameter dictionaries to test:', len(params_arr)\n",
    "\n",
    "    for params_el in params_arr:\n",
    "        score = test_it(params_el, max_rounds, n_folds)\n",
    "        if score < min_score:\n",
    "                print 'new low score:', score\n",
    "                min_score = score\n",
    "                min_params = copy.deepcopy(params_el)\n",
    "    print min_score, str(min_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_orig = {'max_depth':7, \n",
    "               'min_child_weight': 5.3,\n",
    "               'eta':.025, \n",
    "               'silent':1, \n",
    "               'objective':'reg:linear', \n",
    "               'eval_metric': 'rmse',\n",
    "               'subsample': .9,\n",
    "               'colsample_bytree': .6,\n",
    "               'gamma': 0,\n",
    "               'reg_alpha': 0\n",
    "         }\n",
    "\n",
    "\n",
    "\n",
    "# GRID SEARCH - Change the params_dict to test different parameters\n",
    "\n",
    "params_dict = {\n",
    "    'colsample_bytree': [.6,.8,1],\n",
    "    'max_depth': [5,7,9],\n",
    "    'subsample': [.8,.9,1],\n",
    "    'colsample_bytree': [.6,.8,1],\n",
    "    'eta': [.13]\n",
    "}\n",
    "\n",
    "n_folds = 10\n",
    "max_rounds = 1500\n",
    "\n",
    "grid_search(params_dict, params_orig, n_folds, max_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kf_train(num_kf, t_ds, targets, n_folds, num_rounds, params):\n",
    "    \"\"\"Function to train num_kf kfold instances.  Used to blend booster predictions\"\"\"\n",
    "    \n",
    "    targets = np.array(targets)\n",
    "    kf_arr = list()\n",
    "    for i in range(num_kf):\n",
    "        kf_arr.append(KFold(len(t_ds), n_folds = n_folds, shuffle=True, random_state=(int(random.random()*100000))))\n",
    "        \n",
    "    kf = KFold(n_train, n_folds = n_folds, shuffle=True, random_state=442)\n",
    "    \n",
    "    bst_arr = list()\n",
    "    fin_score = 0.0\n",
    "    for k, kf_i in enumerate(kf_arr):\n",
    "        for i, (train_idx, test_idx) in enumerate(kf_i):\n",
    "            dtrain = xgb.DMatrix(t_ds.iloc[train_idx], label=targets[train_idx])\n",
    "            booster = xgb.train(params, dtrain, num_rounds)\n",
    "            dtest = xgb.DMatrix(t_ds.iloc[test_idx])\n",
    "            ypred = booster.predict(dtest)\n",
    "            score = mean_absolute_error(targets[test_idx], ypred)\n",
    "            print(\"Predictions received score: {}\".format(score))\n",
    "            fin_score += score\n",
    "            bst_arr.append(booster)\n",
    "            print 'finished ' + str(i+1) + 'th iteration'\n",
    "    print fin_score / (num_kf*n_folds)\n",
    "    return bst_arr\n",
    "\n",
    "def test_bsts(saved_bsts, targets):\n",
    "    \"\"\"Generates predictions on targets from array of saved_bsts\"\"\"\n",
    "    \n",
    "    dtest = xgb.DMatrix(targets)\n",
    "    ypred_arr = np.ndarray((len(targets),len(saved_bsts)))\n",
    "    for i,bst in enumerate(saved_bsts): \n",
    "        ypred_arr[:,i] = bst.predict(dtest)\n",
    "    ypred = ypred_arr.mean(axis=1)\n",
    "    return ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_orig = {'max_depth':7, \n",
    "               'min_child_weight': 5.3,\n",
    "               'eta':.025, \n",
    "               'silent':1, \n",
    "               'objective':'reg:linear', \n",
    "               'eval_metric': 'rmse',\n",
    "               'subsample': .9,\n",
    "               'colsample_bytree': .6,\n",
    "               'gamma': 0,\n",
    "               'reg_alpha': 0\n",
    "         }\n",
    "\n",
    "num_kf = 1\n",
    "kfolds = 10\n",
    "n_rounds = 691\n",
    "bst_arr3 = kf_train(num_kf, train_df, log_prices, kfolds, n_rounds, params_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dtrain = xgb.DMatrix(train_df, label = log_prices)\n",
    "bst = xgb.train(params_orig, dtrain, 691)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(bst.get_fscore().items(), columns=['feature','importance']).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dtest = xgb.DMatrix(test_df)\n",
    "#ypred = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fin_arrs = bst_arr3\n",
    "ypred = test_bsts(fin_arrs, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_file = pd.read_csv('../housing-prices/sample_submission.csv')\n",
    "print ypred.shape, sub_file.shape\n",
    "sub_file.iloc[:,1] = np.exp(ypred)\n",
    "now = datetime.datetime.now().strftime(\"%d-%m-%y--%H:%M\")\n",
    "sub_file.to_csv('../housing-prices/submissions/my_submission' + now + '.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [nanodegree]",
   "language": "python",
   "name": "Python [nanodegree]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
